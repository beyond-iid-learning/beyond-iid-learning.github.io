<!doctype html><html lang=en><head>
<meta name=generator content="Hugo 0.88.1">
<meta name=date content="2021-09-04T09:39:19Z">
<meta charset=utf-8>
<meta name=HandheldFriendly content="True">
<meta name=MobileOptimized content="320">
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=referrer content="no-referrer">
<meta name=author content="Timothy Gebhard">
<meta name=description content="The seminar highlights challenges that arise due to the interaction of learning algorithms with (dynamic) environments. It will be divided into two parts: The first part summarizes the basics of statistical learning theory, game theory, causal inference, and dynamical systems in four lectures. This sets the stage for the second part, where distinguished speakers will present selected aspects in greater detail and link them to their current research.">
<meta name=keywords content="causal inference,adaptive decision-making,reinforcement learning,game theory,meta learning,interactions with humans">
<title>Lectures</title>
<meta property="og:title" content="Lectures">
<meta property="og:type" content="website">
<meta property="og:description" content="The seminar highlights challenges that arise due to the interaction of learning algorithms with (dynamic) environments. It will be divided into two parts: The first part summarizes the basics of statistical learning theory, game theory, causal inference, and dynamical systems in four lectures. This sets the stage for the second part, where distinguished speakers will present selected aspects in greater detail and link them to their current research.">
<meta name=twitter:title content>
<link rel=canonical href=https://beyond-iid-learning.xyz/lectures/>
<link rel=stylesheet href=https://beyond-iid-learning.xyz/styles.css>
<link rel=apple-touch-icon sizes=180x180 href=https://beyond-iid-learning.xyz/apple-touch-icon.png>
<link rel=icon type=image/png sizes=32x32 href=https://beyond-iid-learning.xyz/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=https://beyond-iid-learning.xyz/favicon-16x16.png>
<link rel=manifest href=https://beyond-iid-learning.xyz/site.webmanifest>
</head><body><section id=header>
<h1><a href=https://beyond-iid-learning.xyz/>Beyond i.i.d. learning:<br> Causality, dynamics, and interactions</a></h1>
<div id=navigation>
<ul>
<li><strong><a href=https://beyond-iid-learning.xyz/announcements>Announcements</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/syllabus>Syllabus</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/lectures>Lectures</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/faq>FAQ</a></strong></li>
</ul>
</div>
</section><section id=content>
<p>On this page, you will find an overview of the lectures and the materials that we plan to cover in the seminar.
For each week, we also list some recommended preparatory reading that you should read <em>before</em> the lecture.</p>
<p>In case you want to add the lectures to your calendar, <a href=https://beyond-iid-learning.xyz/lectures/index.ics>we are providing an ICS file</a> to which you can subscribe (e.g., <code>File</code> → <code>New Calendar Subscription</code> in the default Calendar app on macOS).</p>
<hr>
<section>
<small class=lecture-number>
— Lecture 0 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-00/>Introduction</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://www.is.mpg.de/~bs>Bernhard Schölkopf</a>
(MPI-IS),
<a href=https://sites.google.com/view/mmuehlebach/>Michael Muehlebach</a>
(MPI-IS)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-09-22T17:30:00>September 22, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-09-22T17:30:00>17:30</time>–<time datetime=2021-09-22T18:00:00>18:00</time> (Zurich time)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
Brief meeting, discussion of course schedule, exam.
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 1 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-01/>A brief overview of statistical learning theory</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://sites.google.com/view/mmuehlebach/>Michael Muehlebach</a>
(MPI-IS)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-09-29T16:15:00>September 29, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-09-29T16:15:00>16:15</time>–<time datetime=2021-09-29T18:00:00>18:00</time> (Zurich time)</td>
</tr>
<tr>
<td>Notes:</td>
<td><a href=https://beyond-iid-learning.xyz/notes/lecture-01.pdf>Click here to download!</a></td>
</tr>
<tr>
<td>Recording:</td>
<td><a href=https://video.ethz.ch/lectures/d-infk/2021/autumn/263-5156-00L/a1ba36a7-b9d9-4d8e-a400-9d5a64da0e86.html>Click here to view!</a> (only for ETH members)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
The lecture will summarize the main ideas of statistical learning theory.
We will revisit the standard generalization bounds that characterize the difference between true and empirical risk.
We will critically discuss the underlying assumptions and show examples where these are violated.
We will also discuss the dependence of the bounds on the number of parameters, which is important for understanding the success of overparametrization in today’s machine learning practice.
</section>
<section class=references>
<h4>Recommended reading:</h4>
<ul>
<li>von Luxburg, U., & Schölkopf, B. (2011). <em>Statistical Learning Theory: Models, Concepts, and Results.</em> In: <em>Handbook of the History of Logic, Volume 10: Inductive Logic</em> (pp. 651–706). Amsterdam: Elsevier. DOI: <a href=https://doi.org/10.1016/b978-0-444-52936-7.50016-1>10.1016/b978-0-444-52936-7.50016-1</a>.</li>
</ul>
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 2 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-02/>A brief overview of game theory</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://sites.google.com/view/mmuehlebach/>Michael Muehlebach</a>
(MPI-IS)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-10-06T16:15:00>October 6, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-10-06T16:15:00>16:15</time>–<time datetime=2021-10-06T18:00:00>18:00</time> (Zurich time)</td>
</tr>
<tr>
<td>Notes:</td>
<td><a href=https://beyond-iid-learning.xyz/notes/lecture-02.pdf>Click here to download!</a></td>
</tr>
<tr>
<td>Recording:</td>
<td><a href=https://video.ethz.ch/lectures/d-infk/2021/autumn/263-5156-00L/9967ef5e-cf6d-45f7-9280-febf0e434ef2.html>Click here to view!</a> (only for ETH members)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
The lecture will summarize key ideas in game theory.
Game theory provides a means for modelling interactions between machine learning algorithms and their environment.
We will revisit zero-sum games and von Neumann’s minimax theorem and introduce the concept of Nash equilibria.
We will then discuss repeated games and adaptive decision-making algorithms (follow the leader, follow a random leader, multiplicative weights).
</section>
<section class=references>
<h4>Recommended reading:</h4>
<ul>
<li>Karlin, A. R., & Peres, Y. (2017). <em>Game theory, alive.</em> American Mathematical Society. ISBN: 978-1-4704-1982-0. <a href=https://homes.cs.washington.edu/~karlin/GameTheoryBook.pdf>PDF version available online.</a> <strong>[Chapter 2: Section 2.1–2.3; Chapter 18: Section 18.1–18.3]</strong></li>
</ul>
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 3 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-03/>Introduction to Causality</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://www.is.mpg.de/~bs>Bernhard Schölkopf</a>
(MPI-IS)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-10-13T16:15:00>October 13, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-10-13T16:15:00>16:15</time>–<time datetime=2021-10-13T18:00:00>18:00</time> (Zurich time)</td>
</tr>
<tr>
<td>Slides:</td>
<td><a href=https://beyond-iid-learning.xyz/slides/lecture-03.pdf>Click here to download!</a></td>
</tr>
<tr>
<td>Recording:</td>
<td><a href=https://video.ethz.ch/lectures/d-infk/2021/autumn/263-5156-00L/bcffc82a-b9d3-47d6-bc77-37dfab177e7a.html>Click here to view!</a> (only for ETH members)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
The two fields of machine learning and graphical causality arose and developed separately.
However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other.
In the present paper, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research.
This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given.
A central problem for AI and causality is, thus, causal representation learning, the discovery of high-level causal variables from low-level observations.
</section>
<section class=references>
<h4>Recommended reading:</h4>
<ul>
<li>Schölkopf, B. et al. (2021). <em>Towards causal representation learning.</em> <a href=https://arxiv.org/abs/2102.11107>arXiv:2102.11107</a>.</li>
</ul>
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 4 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-04/>New results in adaptive decision-making</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://las.inf.ethz.ch/krausea>Andreas Krause</a>
(ETH Zürich)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-10-20T16:15:00>October 20, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-10-20T16:15:00>16:15</time>–<time datetime=2021-10-20T18:00:00>18:00</time> (Zurich time)</td>
</tr>
<tr>
<td>Notes:</td>
<td><a href=https://beyond-iid-learning.xyz/notes/lecture-04.pdf>Click here to download!</a></td>
</tr>
<tr>
<td>Recording:</td>
<td><a href=https://video.ethz.ch/lectures/d-infk/2021/autumn/263-5156-00L/445af708-bd98-490c-ad7d-531dde3ffca6.html>Click here to view!</a> (only for ETH members)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
This lecture will provide an introduction to (non-statistical) online learning and multi-armed bandits.
We will discuss the multiplicative weights algorithm <em>Hedge</em>, and its partial information counterpart <em>EXP3</em>, as well as some applications to learning in games.
</section>
<section class=references>
<h4>Recommended reading:</h4>
<ul>
<li>Hazan, E. (2019). <em>Introduction to Online Convex Optimization</em>. <a href=https://arxiv.org/pdf/1909.05207.pdf>arXiv:1909.05207v1</a>. <strong>[Chapter 6.2]</strong></li>
<li>Sessa, P. G., et al. (2019). <em>No-Regret Learning in Unknown Games with Correlated Payoffs</em>. <a href=https://las.inf.ethz.ch/files/sessa19noregret.pdf>Available online.</a></li>
</ul>
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 5 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-05/>A brief overview of dynamics and control</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://sites.google.com/view/mmuehlebach/>Michael Muehlebach</a>
(MPI-IS)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-10-27T16:15:00>October 27, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-10-27T16:15:00>16:15</time>–<time datetime=2021-10-27T18:00:00>18:00</time> (Zurich time)</td>
</tr>
<tr>
<td>Notes:</td>
<td><a href=https://beyond-iid-learning.xyz/notes/lecture-05.pdf>Click here to download!</a></td>
</tr>
<tr>
<td>Recording:</td>
<td><a href=https://video.ethz.ch/lectures/d-infk/2021/autumn/263-5156-00L/0116cbcb-dadf-4081-8d30-fa2c3d8e0817.html>Click here to view!</a> (only for ETH members)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
The lecture will summarize the basics of dynamical systems and control theory.
We will discuss discrete-time and continuous-time dynamical systems, introduce the concept of equilibria and Lyapunov stability.
An important aspect of the lecture will be to emphasize the difference between noise and structural (epistemic) uncertainty and show how uncertainty can be reduced with feedback.
We will also discuss connections to game theory and generalization (Lecture 1).
</section>
<section class=references>
<h4>Recommended reading:</h4>
<ul>
<li>Strogatz, S. H. (2015). <em>Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering.</em> 2nd edition. Boca Raton: CRC Press. DOI: <a href=https://doi.org/10.1201/9780429492563>10.1201/9780429492563</a>. <strong>[Chapter 2]</strong></li>
</ul>
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 6 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-06/>Developing Counterfactual Explanations</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href="https://scholar.google.com/citations?user=RM2sHhYAAAAJ&hl=en">Chris Russell</a>
(Amazon)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-11-03T16:15:00>November 3, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-11-03T16:15:00>16:15</time>–<time datetime=2021-11-03T18:00:00>18:00</time> (Zurich time)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
Counterfactual Explanations are a relatively recent form of explanation designed to explicitly meet the needs of non-technical users.
Unlike methods such as Shapley values that providing measures of the relative importance of features, counterfactual explanations offer simple direct explanations of the form:
You were not offered a loan because your salary was <span>$</span>30k, if it had been <span>$</span>45k instead, you would have been offered the loan.
These forms of explanation are very popular in legal and governance areas of AI, and are cited in the guidelines to the GDPR.
We will discuss the development of counterfactuals explanations, including why previous forms of explanation are often unsuitable for end-users, and the limitations of counterfactual explanations, and what they can and can not tell you, and the challenges of extending them to high-dimensional problems in computer vision.
</section>
<section class=references>
<h4>Recommended reading:</h4>
<ul>
<li>Wachter, S., et al. (2018). <em>Counterfactual explanations without opening the black box: automated decisions and the GDPR.</em> Harvard Journal of Law & Technology, 31(2). <a href=https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pdf>Available online.</a> <strong>[Chapters I–IV]</strong></li>
<li>Elliott, A. et al. (2021). <em>Explaining Classifiers using Adversarial Perturbations on the Perceptual Ball.</em> <a href=https://openaccess.thecvf.com/content/CVPR2021/papers/Elliott_Explaining_Classifiers_Using_Adversarial_Perturbations_on_the_Perceptual_Ball_CVPR_2021_paper.pdf>Available online.</a></li>
</ul>
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 7 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-07/>TBA</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=http://people.csail.mit.edu/costis/>Constantinos Daskalakis</a>
(MIT)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-11-10T16:15:00>November 10, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-11-10T16:15:00>16:15</time>–<time datetime=2021-11-10T18:00:00>18:00</time> (Zurich time)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
TBA
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 8 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-08/>TBA</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=http://faculty.washington.edu/kutz/>Nathan Kutz</a>
(University of Washington)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-11-17T16:15:00>November 17, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-11-17T16:15:00>16:15</time>–<time datetime=2021-11-17T18:00:00>18:00</time> (Zurich time)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
TBA
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 9 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-09/>TBA</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=http://georg.playfulmachines.com/>Georg Martius</a>
(MPI-IS)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-11-24T16:15:00>November 24, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-11-24T16:15:00>16:15</time>–<time datetime=2021-11-24T18:00:00>18:00</time> (Zurich time)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
TBA
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 10 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-10/>TBA</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://janzing.github.io/>Dominik Janzing</a>
(Amazon)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-12-01T16:15:00>December 1, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-12-01T16:15:00>16:15</time>–<time datetime=2021-12-01T18:00:00>18:00</time> (Zurich time)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
TBA
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 11 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-11/>TBA</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://web.stanford.edu/~lmackey/>Lester Mackey</a>
(Stanford, Microsoft Research New England)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-12-08T16:15:00>December 8, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-12-08T16:15:00>16:15</time>–<time datetime=2021-12-08T18:00:00>18:00</time> (Zurich time)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
TBA
</section>
</section>
<hr>
<section>
<small class=lecture-number>
— Lecture 12 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-12/>TBA</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://people.mpi-sws.org/~manuelgr/>Manuel Gomez Rodriguez</a>
(MPI-SWS)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-12-15T16:15:00>December 15, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-12-15T16:15:00>16:15</time>–<time datetime=2021-12-15T18:00:00>18:00</time> (Zurich time)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
TBA
</section>
</section>
</section>
<div id=footer>
Made with <a href=https://gohugo.io/>Hugo</a> and hosted on <a href=https://github.com/beyond-iid-learning/beyond-iid-learning.github.io>GitHub</a>.
</div>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css integrity=sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn crossorigin=anonymous>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.js integrity=sha384-ov99pRO2tAc0JuxTVzf63RHHeQTJ0CIawbDZFiFTzB07aqFZwEu2pz4uzqL+5OPG crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script>
</body>
</html>