<!doctype html><html lang=en><head>
<meta name=generator content="Hugo 0.90.1">
<meta name=date content="2021-12-10T10:56:41Z">
<meta charset=utf-8>
<meta name=HandheldFriendly content="True">
<meta name=MobileOptimized content="320">
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=referrer content="no-referrer">
<meta name=author content="Timothy Gebhard">
<meta name=description content="The seminar highlights challenges that arise due to the interaction of learning algorithms with (dynamic) environments. It will be divided into two parts: The first part summarizes the basics of statistical learning theory, game theory, causal inference, and dynamical systems in four lectures. This sets the stage for the second part, where distinguished speakers will present selected aspects in greater detail and link them to their current research.">
<meta name=keywords content="causal inference,adaptive decision-making,reinforcement learning,game theory,meta learning,interactions with humans">
<title>Causal insights from merging data sets and merging data sets via causal insights</title>
<meta property="og:title" content="Causal insights from merging data sets and merging data sets via causal insights">
<meta property="og:type" content="website">
<meta property="og:description" content="The seminar highlights challenges that arise due to the interaction of learning algorithms with (dynamic) environments. It will be divided into two parts: The first part summarizes the basics of statistical learning theory, game theory, causal inference, and dynamical systems in four lectures. This sets the stage for the second part, where distinguished speakers will present selected aspects in greater detail and link them to their current research.">
<meta name=twitter:title content>
<link rel=canonical href=https://beyond-iid-learning.xyz/lectures/lecture-10/>
<link rel=stylesheet href=https://beyond-iid-learning.xyz/styles.css>
<link rel=apple-touch-icon sizes=180x180 href=https://beyond-iid-learning.xyz/apple-touch-icon.png>
<link rel=icon type=image/png sizes=32x32 href=https://beyond-iid-learning.xyz/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=https://beyond-iid-learning.xyz/favicon-16x16.png>
<link rel=manifest href=https://beyond-iid-learning.xyz/site.webmanifest>
</head><body><section id=header>
<h1><a href=https://beyond-iid-learning.xyz/>Beyond i.i.d. learning:<br> Causality, dynamics, and interactions</a></h1>
<div id=navigation>
<ul>
<li><strong><a href=https://beyond-iid-learning.xyz/announcements>Announcements</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/syllabus>Syllabus</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/lectures>Lectures</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/faq>FAQ</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/exam>Exam</a></strong></li>
</ul>
</div>
</section><section id=content>
<section id=content>
<section>
<small class=lecture-number>
— Lecture 10 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-10/>Causal insights from merging data sets and merging data sets via causal insights</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=https://janzing.github.io/>Dominik Janzing</a>
(Amazon)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-12-01T16:15:00>December 1, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-12-01T16:15:00>16:15</time>–<time datetime=2021-12-01T18:00:00>18:00</time> (Zurich time)</td>
</tr>
<tr>
<td>Recording:</td>
<td><a href=https://video.ethz.ch/lectures/d-infk/2021/autumn/263-5156-00L/ace23df3-60a2-4a61-a6eb-9c4484d16c3a.html>Click here to view!</a> (only for ETH members)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
While humans often draw causal conclusions from putting observations into the broader context of causal knowledge, AI still needs to develop these techniques.
I show how causal insights can be obtained from the synergy of datasets referring to different sets of variables and argue that causal hypotheses then predict joint properties of variables that have never been observed together.
This way, causal discovery becomes a prediction task in which additional variable sets play the role of additional data points in traditional iid learning.
For instance, a causal DAG can be seen as a binary classifier that tells us which conditional independences are valid, which then enables a statistical learning theory for learning DAGs.
I describe &ldquo;Causal MaxEnt&rdquo; (a modified version of MaxEnt that is asymmetric with respect to causal directions) as one potential approach to infer DAGs and properties of the joint distribution from a set of marginal distributions of subsets of variables and derive causal conclusions for toy examples.
</section>
<section class=references>
<h4>Recommended reading:</h4>
<ul>
<li>Janzing, D. (2018): <em>Merging joint distributions via causal model classes with low VC dimension</em>. <a href=https://arxiv.org/abs/1804.03206>arXiv:1804.03206</a>.</li>
<li>Garrido Mejia, S. et al. (2021): <em>Obtaining causal information by merging data sets with MaxEnt.</em> <a href=https://arxiv.org/abs/2107.07640>arXiv:2107.07640</a>. <strong>[optional]</strong></li>
<li>Janzing, D. (2021): <em>Causal versions of Maximum Entropy and Principle of Insufficient Reason</em> <a href=https://arxiv.org/abs/2102.03906>arXiv:2102.03906</a>. <strong>[optional]</strong></li>
</ul>
</section>
</section>
</section>
</section>
<div id=footer>
Made with <a href=https://gohugo.io/>Hugo</a> and hosted on <a href=https://github.com/beyond-iid-learning/beyond-iid-learning.github.io>GitHub</a>.
</div>
</body>
</html>