<!doctype html><html lang=en><head>
<meta name=generator content="Hugo 0.92.0">
<meta name=date content="2022-01-12T08:23:18Z">
<meta charset=utf-8>
<meta name=HandheldFriendly content="True">
<meta name=MobileOptimized content="320">
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=referrer content="no-referrer">
<meta name=author content="Timothy Gebhard">
<meta name=description content="The seminar highlights challenges that arise due to the interaction of learning algorithms with (dynamic) environments. It will be divided into two parts: The first part summarizes the basics of statistical learning theory, game theory, causal inference, and dynamical systems in four lectures. This sets the stage for the second part, where distinguished speakers will present selected aspects in greater detail and link them to their current research.">
<meta name=keywords content="causal inference,adaptive decision-making,reinforcement learning,game theory,meta learning,interactions with humans">
<title>Equilibrium Computation and Machine Learning</title>
<meta property="og:title" content="Equilibrium Computation and Machine Learning">
<meta property="og:type" content="website">
<meta property="og:description" content="The seminar highlights challenges that arise due to the interaction of learning algorithms with (dynamic) environments. It will be divided into two parts: The first part summarizes the basics of statistical learning theory, game theory, causal inference, and dynamical systems in four lectures. This sets the stage for the second part, where distinguished speakers will present selected aspects in greater detail and link them to their current research.">
<meta name=twitter:title content>
<link rel=canonical href=https://beyond-iid-learning.xyz/lectures/lecture-07/>
<link rel=stylesheet href=https://beyond-iid-learning.xyz/styles.css>
<link rel=apple-touch-icon sizes=180x180 href=https://beyond-iid-learning.xyz/apple-touch-icon.png>
<link rel=icon type=image/png sizes=32x32 href=https://beyond-iid-learning.xyz/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=https://beyond-iid-learning.xyz/favicon-16x16.png>
<link rel=manifest href=https://beyond-iid-learning.xyz/site.webmanifest>
</head><body><section id=header>
<h1><a href=https://beyond-iid-learning.xyz/>Beyond i.i.d. learning:<br> Causality, dynamics, and interactions</a></h1>
<div id=navigation>
<ul>
<li><strong><a href=https://beyond-iid-learning.xyz/announcements>Announcements</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/syllabus>Syllabus</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/lectures>Lectures</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/faq>FAQ</a></strong></li>
<li><strong><a href=https://beyond-iid-learning.xyz/exam>Exam</a></strong></li>
</ul>
</div>
</section><section id=content>
<section id=content>
<section>
<small class=lecture-number>
— Lecture 7 —
</small>
<h1>
<a href=https://beyond-iid-learning.xyz/lectures/lecture-07/>Equilibrium Computation and Machine Learning</a>
</h1>
<table class=lecture-table>
<tr>
<td>Lecturer:</td>
<td>
<a href=http://people.csail.mit.edu/costis/>Constantinos Daskalakis</a>
(MIT)
</td>
</tr>
<tr>
<td>Date:</td>
<td><time datetime=2021-11-10T16:15:00>November 10, 2021</time></td>
</tr>
<tr>
<td>Time:</td>
<td><time datetime=2021-11-10T16:15:00>16:15</time>–<time datetime=2021-11-10T18:00:00>18:00</time> (Zurich time)</td>
</tr>
<tr>
<td>Slides:</td>
<td><a href=https://beyond-iid-learning.xyz/slides/lecture-07.pdf>Click here to download!</a></td>
</tr>
<tr>
<td>Recording:</td>
<td><a href=https://video.ethz.ch/lectures/d-infk/2021/autumn/263-5156-00L/83e3cf76-a1fb-41d8-94ed-e6270c2c3008.html>Click here to view!</a> (only for ETH members)</td>
</tr>
</table>
<section class=abstract>
<h4>Abstract:</h4>
Machine learning has recently made significant advances in single-agent learning challenges, much of that progress being fueled by the empirical success of gradient descent-based methods in computing local optima of non-convex optimization problems.
In multi-agent learning challenges, the role of single-objective optimization is played by equilibrium computation.
On this front, however, optimization methods have remained less successful in settings, such as adversarial training and multi-agent reinforcement learning, motivated by deep learning applications.
Gradient-descent based methods commonly fail to identify equilibria, and even computing local approximate equilibria has remained daunting.
We discuss equilibrium computation challenges motivated by machine learning applications through a combination of learning-theoretic, complexity-theoretic, game-theoretic and topological techniques, presenting obstacles and opportunities for machine learning and game theory going forward.
No deep learning / complexity theory knowledge will be assumed for this talk.
</section>
<section class=references>
<h4>Recommended reading:</h4>
<ul>
<li>Daskalakis, C. et al. (2018). <em>Training GANs with Optimism.</em> <a href=https://arxiv.org/abs/1711.00141>arXiv:1711.00141</a>. <strong>[Pages 1–10].</strong></li>
<li>Daskalakis, C. et al. (2020). <em>The Complexity of Constrained Min-Max Optimization.</em> <a href=https://arxiv.org/abs/2009.09623>arXiv:2009.09623</a>. <strong>[Pages 1–8; optional!].</strong></li>
<li>Daskalakis, C. et al. (2021). <em>Near-Optimal No-Regret Learning in General Games.</em> <a href=https://arxiv.org/abs/2108.06924>arXiv:2108.06924</a>. <strong>[Optional!]</strong></li>
</ul>
</section>
</section>
</section>
</section>
<div id=footer>
Made with <a href=https://gohugo.io/>Hugo</a> and hosted on <a href=https://github.com/beyond-iid-learning/beyond-iid-learning.github.io>GitHub</a>.
</div>
</body>
</html>